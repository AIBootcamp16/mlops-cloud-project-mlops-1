# monitoring/dashboard.py
"""
MLOps ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ (Streamlit) - ì‹¤í—˜ ì´ë¦„ ìˆ˜ì • ë²„ì „
"""
import requests
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from mlflow.tracking import MlflowClient
import mlflow
from datetime import datetime, timedelta
from pathlib import Path
import os
import boto3
from io import BytesIO
from urllib.parse import urlparse

# í™˜ê²½ ë³€ìˆ˜
FASTAPI_URL = os.getenv("FASTAPI_URL", "http://fastapi:8000")
MLFLOW_URI = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
S3_BUCKET = os.getenv("S3_BUCKET", "")
S3_PREDICTIONS_PATH = os.getenv("S3_PREDICTIONS_PATH", "predictions/")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="COVID-19 ML ëª¨ë‹ˆí„°ë§",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# MLflow í´ë¼ì´ì–¸íŠ¸
mlflow.set_tracking_uri(MLFLOW_URI)
client = MlflowClient()

# ì‚¬ì´ë“œë°”
st.sidebar.title("âš™ï¸ ì„¤ì •")
st.sidebar.info(f"MLflow URI: {MLFLOW_URI}")
if S3_BUCKET:
    st.sidebar.info(f"S3 Bucket: {S3_BUCKET}")

# âœ… ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì‹¤í—˜ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •
experiment_names = [
    "covid_model_training_integrated",
    "covid_feature_engineering",
    "covid_data_preprocessing",
    "covid_prediction_realtime"
]
experiment_name = st.sidebar.selectbox("Experiment ì„ íƒ", experiment_names)

if st.sidebar.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸ“Š COVID-19 ì˜ˆì¸¡ ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
st.markdown("---")


# ==================== S3 Helper Functions ====================
def _read_csv_from_s3(s3_uri: str) -> pd.DataFrame:
    """S3ì—ì„œ CSV ì§ì ‘ ì½ê¸°"""
    u = urlparse(s3_uri)
    bucket, key = u.netloc, u.path.lstrip("/")
    obj = boto3.client("s3").get_object(Bucket=bucket, Key=key)
    return pd.read_csv(BytesIO(obj["Body"].read()))


def load_latest_prediction_from_s3() -> pd.DataFrame:
    """S3ì—ì„œ ìµœì‹  ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ"""
    if not S3_BUCKET:
        return None

    try:
        s3 = boto3.client("s3")
        paginator = s3.get_paginator("list_objects_v2")

        csv_files = []
        for page in paginator.paginate(Bucket=S3_BUCKET, Prefix=S3_PREDICTIONS_PATH):
            for obj in page.get("Contents", []):
                key = obj["Key"]
                if key.endswith(".csv") and "batch_prediction_" in key:
                    csv_files.append({
                        "key": key,
                        "last_modified": obj["LastModified"],
                        "size": obj["Size"]
                    })

        if not csv_files:
            return None

        latest = max(csv_files, key=lambda x: x["last_modified"])
        st.sidebar.success(f"âœ… S3ì—ì„œ ë¡œë“œ: {os.path.basename(latest['key'])}")

        return _read_csv_from_s3(f"s3://{S3_BUCKET}/{latest['key']}")

    except Exception as e:
        st.sidebar.error(f"S3 ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_latest_prediction_from_mlflow() -> pd.DataFrame:
    """MLflow ì•„í‹°íŒ©íŠ¸ì—ì„œ ìµœì‹  ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ"""
    try:
        # âœ… ì‹¤ì œ ì‹¤í—˜ ì´ë¦„ë“¤ ì‹œë„
        prediction_experiments = [
            "covid_model_training_integrated",
            "covid_prediction_realtime"
        ]

        for exp_name in prediction_experiments:
            try:
                exp = client.get_experiment_by_name(exp_name)
                if not exp:
                    continue

                runs = mlflow.search_runs(
                    [exp.experiment_id],
                    order_by=["start_time DESC"],
                    max_results=5
                )

                if runs.empty:
                    continue

                # ê° ëŸ°ì—ì„œ ì˜ˆì¸¡ CSV ì°¾ê¸°
                for _, run in runs.iterrows():
                    run_id = run["run_id"]
                    try:
                        artifact_paths = ["forecast", "predictions", "results"]

                        for path in artifact_paths:
                            try:
                                dir_path = mlflow.artifacts.download_artifacts(
                                    f"runs:/{run_id}/{path}"
                                )
                                csv_files = [f for f in os.listdir(dir_path)
                                             if f.endswith(".csv")]

                                if csv_files:
                                    csv_file = os.path.join(dir_path, sorted(csv_files)[-1])
                                    df = pd.read_csv(csv_file)
                                    st.sidebar.success(f"âœ… MLflowì—ì„œ ë¡œë“œ: {os.path.basename(csv_file)}")
                                    return df

                            except Exception:
                                continue

                    except Exception:
                        continue

            except Exception:
                continue

        return None

    except Exception as e:
        st.sidebar.error(f"MLflow ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_prediction_results() -> pd.DataFrame:
    """ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ (S3 â†’ MLflow â†’ ë¡œì»¬ ìˆœ)"""

    # 1ìˆœìœ„: S3
    if S3_BUCKET:
        df = load_latest_prediction_from_s3()
        if df is not None:
            return df

    # 2ìˆœìœ„: MLflow
    df = load_latest_prediction_from_mlflow()
    if df is not None:
        return df

    # 3ìˆœìœ„: ë¡œì»¬ ê²½ë¡œ
    predictions_dir = Path("/workspace/data/predictions")
    if not predictions_dir.exists():
        predictions_dir = Path("/tmp/predictions")

    if predictions_dir.exists():
        prediction_files = list(predictions_dir.glob("batch_prediction_*.csv"))
        if prediction_files:
            latest_file = max(prediction_files, key=lambda p: p.stat().st_mtime)
            st.sidebar.info(f"ğŸ“ ë¡œì»¬ì—ì„œ ë¡œë“œ: {latest_file.name}")
            return pd.read_csv(latest_file)

    return None


def get_latest_metrics(experiment_name):
    """ìµœì‹  ì‹¤í—˜ì˜ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°"""
    try:
        experiment = client.get_experiment_by_name(experiment_name)
        if experiment:
            runs = mlflow.search_runs(
                experiment_ids=[experiment.experiment_id],
                order_by=["start_time DESC"],
                max_results=10
            )
            return runs
    except Exception as e:
        st.sidebar.error(f"Experiment ì¡°íšŒ ì‹¤íŒ¨: {e}")
    return []


# ==================== 1. ëª¨ë¸ ì„±ëŠ¥ ì¶”ì  ====================
st.header("1. ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì ")

col1, col2, col3, col4 = st.columns(4)

runs = get_latest_metrics(experiment_name)

if runs:
    latest_run = runs[0]
    metrics = latest_run.data.metrics

    with col1:
        # âœ… ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ì´ë¦„ ì§€ì›
        mae = (metrics.get('test_MAE') or
               metrics.get('best_model_test_mae') or
               metrics.get('random_forest_test_mae') or 0)
        st.metric("MAE", f"{mae:.2f}")

    with col2:
        rmse = (metrics.get('test_RMSE') or
                metrics.get('best_model_test_rmse') or
                metrics.get('random_forest_test_rmse') or 0)
        st.metric("RMSE", f"{rmse:.2f}")

    with col3:
        mape = (metrics.get('test_MAPE') or
                metrics.get('best_model_test_mape') or 0)
        st.metric("MAPE", f"{mape:.2f}%")

    with col4:
        r2 = (metrics.get('test_R2') or
              metrics.get('best_model_test_r2') or
              metrics.get('random_forest_test_r2') or 0)
        st.metric("RÂ²", f"{r2:.4f}")
else:
    st.warning(f"Experiment '{experiment_name}'ì—ì„œ ì‹¤í–‰ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

# ==================== 2. ì„±ëŠ¥ ë³€í™” ì¶”ì  ====================
st.header("2. ğŸ“‰ ì„±ëŠ¥ ë³€í™” ì¶”ì´")

if runs:
    metric_history = []
    for run in runs:
        metrics = run.data.metrics
        metric_history.append({
            'timestamp': datetime.fromtimestamp(run.info.start_time / 1000),
            'run_id': run.info.run_id[:8],
            'MAE': (metrics.get('test_MAE') or
                    metrics.get('best_model_test_mae') or
                    metrics.get('random_forest_test_mae')),
            'RMSE': (metrics.get('test_RMSE') or
                     metrics.get('best_model_test_rmse') or
                     metrics.get('random_forest_test_rmse')),
            'R2': (metrics.get('test_R2') or
                   metrics.get('best_model_test_r2') or
                   metrics.get('random_forest_test_r2'))
        })

    df_metrics = pd.DataFrame(metric_history)
    # None ê°’ ì œê±°
    df_metrics = df_metrics.dropna(subset=['MAE', 'R2'])

    if not df_metrics.empty and len(df_metrics) > 1:
        col1, col2 = st.columns(2)

        with col1:
            fig_mae = px.line(
                df_metrics,
                x='timestamp',
                y='MAE',
                title='MAE ë³€í™” ì¶”ì´',
                markers=True,
                hover_data=['run_id']
            )
            fig_mae.update_layout(xaxis_title='ì‹œê°„', yaxis_title='MAE')
            st.plotly_chart(fig_mae, use_container_width=True)

        with col2:
            fig_r2 = px.line(
                df_metrics,
                x='timestamp',
                y='R2',
                title='RÂ² ë³€í™” ì¶”ì´',
                markers=True,
                hover_data=['run_id']
            )
            fig_r2.update_layout(xaxis_title='ì‹œê°„', yaxis_title='RÂ²')
            st.plotly_chart(fig_r2, use_container_width=True)
    else:
        st.info("ì„±ëŠ¥ ì¶”ì´ë¥¼ ë³´ë ¤ë©´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")

# ==================== 3. ìµœì‹  ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ ====================
st.header("3. ğŸ”® ìµœì‹  ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼")

try:
    df_pred = load_prediction_results()

    if df_pred is not None:
        if 'date' in df_pred.columns:
            df_pred['date'] = pd.to_datetime(df_pred['date'])
            st.success(f"ğŸ“Š ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(df_pred)} rows)")

        pred_col = None
        for col in ['predicted_new_cases', 'yhat', 'prediction']:
            if col in df_pred.columns:
                pred_col = col
                break

        if pred_col:
            fig_pred = px.line(
                df_pred,
                x='date',
                y=pred_col,
                title='í–¥í›„ ì˜ˆì¸¡',
                markers=True
            )
            fig_pred.update_layout(
                xaxis_title='ë‚ ì§œ',
                yaxis_title='ì˜ˆìƒ ì‹ ê·œ í™•ì§„ì ìˆ˜',
                hovermode='x unified'
            )
            st.plotly_chart(fig_pred, use_container_width=True)

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í‰ê·  ì˜ˆì¸¡ê°’", f"{df_pred[pred_col].mean():.0f}")
            with col2:
                st.metric("ìµœëŒ€ ì˜ˆì¸¡ê°’", f"{df_pred[pred_col].max():.0f}")
            with col3:
                st.metric("ìµœì†Œ ì˜ˆì¸¡ê°’", f"{df_pred[pred_col].min():.0f}")

            with st.expander("ğŸ“‹ ì˜ˆì¸¡ ë°ì´í„° ë³´ê¸°"):
                st.dataframe(df_pred, use_container_width=True)
        else:
            st.warning("ì˜ˆì¸¡ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.dataframe(df_pred.head())
    else:
        st.warning("ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("Airflowì—ì„œ `covid_batch_prediction` DAGë¥¼ ì‹¤í–‰í•˜ë©´ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤.")

except Exception as e:
    st.error(f"ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    with st.expander("ì—ëŸ¬ ìƒì„¸"):
        import traceback

        st.code(traceback.format_exc())

# ==================== 4. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ====================
st.header("4. ğŸ·ï¸ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬")

try:
    models = client.search_registered_models()

    if models:
        for model in models:
            with st.expander(f"ğŸ“¦ {model.name}"):
                versions = client.search_model_versions(f"name='{model.name}'")

                if versions:
                    version_data = []
                    for version in versions[:5]:
                        version_data.append({
                            'Version': version.version,
                            'Stage': version.current_stage,
                            'Status': version.status,
                            'Created': datetime.fromtimestamp(int(version.creation_timestamp) / 1000).strftime(
                                '%Y-%m-%d %H:%M')
                        })

                    df_versions = pd.DataFrame(version_data)
                    st.dataframe(df_versions, use_container_width=True)
                else:
                    st.info("ë“±ë¡ëœ ë²„ì „ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ==================== 5. ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ ====================
st.header("5. ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ")

col1, col2, col3 = st.columns(3)

with col1:
    try:
        client.search_experiments()
        st.success("âœ… MLflow ì—°ê²° ì •ìƒ")
    except Exception as e:
        st.error("âŒ MLflow ì—°ê²° ì‹¤íŒ¨")

with col2:
    if runs:
        last_run_time = datetime.fromtimestamp(runs[0].info.start_time / 1000)
        hours_ago = (datetime.now() - last_run_time).total_seconds() / 3600

        if hours_ago < 24:
            st.success(f"ğŸ• ë§ˆì§€ë§‰ ì‹¤í–‰: {hours_ago:.1f}ì‹œê°„ ì „")
        else:
            st.warning(f"âš ï¸ ë§ˆì§€ë§‰ ì‹¤í–‰: {hours_ago / 24:.1f}ì¼ ì „")
    else:
        st.info("âš ï¸ ì‹¤í–‰ ê¸°ë¡ ì—†ìŒ")

with col3:
    if S3_BUCKET:
        try:
            s3 = boto3.client("s3")
            s3.head_bucket(Bucket=S3_BUCKET)
            st.success("âœ… S3 ì—°ê²° ì •ìƒ")
        except Exception:
            st.error("âŒ S3 ì—°ê²° ì‹¤íŒ¨")
    else:
        st.info("ğŸ“¦ S3 ë¯¸ì„¤ì •")

# ==================== 6. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ====================
st.header("6. ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡")

col1, col2 = st.columns([2, 1])

with col1:
    prediction_date = st.date_input("ì˜ˆì¸¡ ë‚ ì§œ ì„ íƒ", datetime.now().date())

with col2:
    st.write("")
    st.write("")
    if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
        try:
            response = requests.post(
                f"{FASTAPI_URL}/predict",
                json={"date": prediction_date.strftime("%Y-%m-%d")},
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
                st.metric(
                    f"{prediction_date} ì˜ˆìƒ ì‹ ê·œ í™•ì§„ì",
                    f"{result['predicted_new_cases']:,}ëª…"
                )

                with st.expander("ğŸ“Š ì˜ˆì¸¡ ìƒì„¸ ì •ë³´"):
                    st.json(result)
            else:
                st.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {response.text}")
        except Exception as e:
            st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

st.markdown("---")
st.caption("ğŸ“Š COVID-19 MLOps Dashboard v2.0 | Powered by Streamlit & MLflow")

# ì‚¬ì´ë“œë°”
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“– ê°€ì´ë“œ")
st.sidebar.markdown("""
**ì‹¤í—˜ ëª©ë¡:**
- `covid_model_training_integrated`: ëª¨ë¸ í›ˆë ¨
- `covid_feature_engineering`: í”¼ì²˜ ìƒì„±
- `covid_data_preprocessing`: ë°ì´í„° ì „ì²˜ë¦¬
- `covid_prediction_realtime`: ì‹¤ì‹œê°„ ì˜ˆì¸¡

**ë°ì´í„° ì†ŒìŠ¤:**
- S3 ë²„í‚· (ìš°ì„ )
- MLflow ì•„í‹°íŒ©íŠ¸
- ë¡œì»¬ ê²½ë¡œ (í´ë°±)

**ë§í¬:**
- [MLflow UI](http://localhost:5000)
- [Airflow UI](http://localhost:8080)
- [FastAPI Docs](http://localhost:8000/docs)
""")